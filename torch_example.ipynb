{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Class 선언\n",
    "- Data: Spam베이스라는 57개의 feature을 통해서 spam이메일인지 아닌지 여부를 확인하는 데이터셋, github 참고 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코렙용\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# torch dataloader\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "#train_test_split\n",
    "class SpamDataloader(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "\n",
    "\n",
    "class Spam:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_dir = 'src/dataset/spambase' + '/spambase.data'\n",
    "\n",
    "        pass\n",
    "\n",
    "    def create_data(self):\n",
    "        X = pd.read_csv(self.train_dir, sep=',', header=None)\n",
    "        #data.dropna(axis=1, how='all', inplace=True)\n",
    "        X=X.values\n",
    "        Y=X[:,-1]\n",
    "        X=X[:,:-1]\n",
    "        Y = Y.astype(int)\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "        X_train = torch.tensor(X_train).float()\n",
    "        Y_train = torch.tensor(Y_train).float()\n",
    "        X_test = torch.tensor(X_test).float()\n",
    "        Y_test = torch.tensor(Y_test).float()\n",
    "        Spam_train = SpamDataloader(X_train, Y_train)\n",
    "        Spam_test = SpamDataloader(X_test, Y_test)\n",
    "        return Spam_train, Spam_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SimpleNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: batch_size x 10\n",
    "        x = self.linear1(x)\n",
    "        #question\n",
    "        # batchsize x 5\n",
    "        x = self.linear2(x)\n",
    "        # x: batch_size x 1\n",
    "        x = self.sigmoid(x)\n",
    "        # x: batch_size x 1\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Class 선언: Training과 Testing 둘다 진행가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer():\n",
    "\n",
    "    def __init__(self, model, dataloader, optimizer, loss_fn,device):\n",
    "        # model, dataloader, optimizer, loss_fn\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.device = device\n",
    "        #self.model=self.model.to(device) #  move the model to the device\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            for (x, y) in self.dataloader:\n",
    "                x=x.to(self.device)\n",
    "                y=y.to(self.device)\n",
    "                #print(x.device)\n",
    "                y_pred = self.model(x)\n",
    "                y_pred = y_pred.squeeze()\n",
    "                loss = self.loss_fn(y_pred, y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "\n",
    "            print(\"Epoch: {}, Loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "    def test(self,test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            for (x, y) in test_dataloader:\n",
    "                x=x.to(self.device)\n",
    "                y=y.to(self.device)\n",
    "                y_pred = self.model(x)\n",
    "                y_pred = y_pred.squeeze()\n",
    "                loss = self.loss_fn(y_pred, y)\n",
    "                print(\"Test Loss: {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실제 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.9076948165893555\n",
      "Epoch: 1, Loss: 0.6952906250953674\n",
      "Epoch: 2, Loss: 0.4539429247379303\n",
      "Epoch: 3, Loss: 0.9177824258804321\n",
      "Epoch: 4, Loss: 0.5577143430709839\n",
      "Epoch: 5, Loss: 0.49743854999542236\n",
      "Epoch: 6, Loss: 0.502269983291626\n",
      "Epoch: 7, Loss: 0.5577268600463867\n",
      "Epoch: 8, Loss: 0.4853273034095764\n",
      "Epoch: 9, Loss: 0.5292458534240723\n",
      "Epoch: 10, Loss: 0.43183383345603943\n",
      "Epoch: 11, Loss: 0.4347705543041229\n",
      "Epoch: 12, Loss: 0.4310908615589142\n",
      "Epoch: 13, Loss: 0.3465205430984497\n",
      "Epoch: 14, Loss: 0.3950994610786438\n",
      "Epoch: 15, Loss: 0.45020347833633423\n",
      "Epoch: 16, Loss: 0.35658490657806396\n",
      "Epoch: 17, Loss: 0.4022830128669739\n",
      "Epoch: 18, Loss: 0.30515217781066895\n",
      "Epoch: 19, Loss: 0.43259096145629883\n",
      "Epoch: 20, Loss: 0.35360249876976013\n",
      "Epoch: 21, Loss: 0.35897523164749146\n",
      "Epoch: 22, Loss: 0.38569721579551697\n",
      "Epoch: 23, Loss: 0.36042067408561707\n",
      "Epoch: 24, Loss: 0.43549373745918274\n",
      "Epoch: 25, Loss: 0.2971787452697754\n",
      "Epoch: 26, Loss: 0.2725640833377838\n",
      "Epoch: 27, Loss: 0.28524863719940186\n",
      "Epoch: 28, Loss: 0.28196999430656433\n",
      "Epoch: 29, Loss: 0.22859865427017212\n",
      "Epoch: 30, Loss: 0.4868338108062744\n",
      "Epoch: 31, Loss: 0.2850804924964905\n",
      "Epoch: 32, Loss: 0.25960877537727356\n",
      "Epoch: 33, Loss: 0.2719217836856842\n",
      "Epoch: 34, Loss: 0.28238755464553833\n",
      "Epoch: 35, Loss: 0.3249170780181885\n",
      "Epoch: 36, Loss: 0.33859747648239136\n",
      "Epoch: 37, Loss: 0.40642890334129333\n",
      "Epoch: 38, Loss: 0.3102724552154541\n",
      "Epoch: 39, Loss: 0.2021343857049942\n",
      "Epoch: 40, Loss: 0.2649787366390228\n",
      "Epoch: 41, Loss: 0.32368168234825134\n",
      "Epoch: 42, Loss: 0.2949320673942566\n",
      "Epoch: 43, Loss: 0.30423033237457275\n",
      "Epoch: 44, Loss: 0.2617836594581604\n",
      "Epoch: 45, Loss: 0.20095422863960266\n",
      "Epoch: 46, Loss: 0.2716004550457001\n",
      "Epoch: 47, Loss: 0.22747576236724854\n",
      "Epoch: 48, Loss: 0.24608559906482697\n",
      "Epoch: 49, Loss: 0.39913302659988403\n",
      "Test Loss: 0.28147831559181213\n"
     ]
    }
   ],
   "source": [
    "spam = Spam()\n",
    "Spam_train,Spam_test = spam.create_data() # X: train, Y: train_label, X: test\n",
    "\n",
    "# Create a dataloader\n",
    "train_dataloader = DataLoader(Spam_train, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(Spam_test, batch_size=3000, shuffle=True) # batch_size = 3000을 한 이유는 test data 전체를 한번에 testing 하기 위함임. \n",
    "\n",
    "\n",
    "# Create a model\n",
    "model = SimpleNN(input_dim=57, hidden_dim=10,output_dim= 1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Create an optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# Create a loss function\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "model=model.to(device)\n",
    "# Create a trainer\n",
    "trainer = Trainer(model, train_dataloader, optimizer, loss_fn,device)\n",
    "# Train the model\n",
    "trainer.train(num_epochs=50)\n",
    "# Test the model\n",
    "trainer.test(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.4391304552555084\n",
      "Epoch: 1, Loss: 0.19496846199035645\n",
      "Epoch: 2, Loss: 1.0545012950897217\n",
      "Epoch: 3, Loss: 0.27353841066360474\n",
      "Epoch: 4, Loss: 0.1685471534729004\n",
      "Epoch: 5, Loss: 0.3707175850868225\n",
      "Epoch: 6, Loss: 0.23777194321155548\n",
      "Epoch: 7, Loss: 0.19678068161010742\n",
      "Epoch: 8, Loss: 0.253887802362442\n",
      "Epoch: 9, Loss: 0.21503892540931702\n",
      "Epoch: 10, Loss: 0.20548155903816223\n",
      "Epoch: 11, Loss: 0.1486048400402069\n",
      "Epoch: 12, Loss: 0.6156580448150635\n",
      "Epoch: 13, Loss: 0.14855632185935974\n",
      "Epoch: 14, Loss: 0.13399551808834076\n",
      "Epoch: 15, Loss: 0.13901634514331818\n",
      "Epoch: 16, Loss: 0.389761745929718\n",
      "Epoch: 17, Loss: 0.2179463505744934\n",
      "Epoch: 18, Loss: 0.15224000811576843\n",
      "Epoch: 19, Loss: 0.21589359641075134\n",
      "Epoch: 20, Loss: 0.23532156646251678\n",
      "Epoch: 21, Loss: 0.33786511421203613\n",
      "Epoch: 22, Loss: 0.19920089840888977\n",
      "Epoch: 23, Loss: 3.5299856662750244\n",
      "Epoch: 24, Loss: 0.1244935467839241\n",
      "Epoch: 25, Loss: 0.15238313376903534\n",
      "Epoch: 26, Loss: 0.16849815845489502\n",
      "Epoch: 27, Loss: 0.18987269699573517\n",
      "Epoch: 28, Loss: 0.2504851818084717\n",
      "Epoch: 29, Loss: 0.0996471643447876\n",
      "Epoch: 30, Loss: 0.32018357515335083\n",
      "Epoch: 31, Loss: 0.1718611717224121\n",
      "Epoch: 32, Loss: 0.3664412498474121\n",
      "Epoch: 33, Loss: 0.25196412205696106\n",
      "Epoch: 34, Loss: 0.2708435654640198\n",
      "Epoch: 35, Loss: 0.12189877033233643\n",
      "Epoch: 36, Loss: 0.07795169949531555\n",
      "Epoch: 37, Loss: 0.4735828936100006\n",
      "Epoch: 38, Loss: 0.1551993191242218\n",
      "Epoch: 39, Loss: 0.20762217044830322\n",
      "Epoch: 40, Loss: 0.3152397572994232\n",
      "Epoch: 41, Loss: 0.0648837462067604\n",
      "Epoch: 42, Loss: 0.23993465304374695\n",
      "Epoch: 43, Loss: 0.26108813285827637\n",
      "Epoch: 44, Loss: 0.15036292374134064\n",
      "Epoch: 45, Loss: 0.6795843839645386\n",
      "Epoch: 46, Loss: 0.3863852620124817\n",
      "Epoch: 47, Loss: 0.1516704112291336\n",
      "Epoch: 48, Loss: 0.10612927377223969\n",
      "Epoch: 49, Loss: 3.372662305831909\n",
      "Test Loss: 0.23842400312423706\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Spam Classifier')\n",
    "parser.add_argument('--num_hidden', type=int, default=10, help='number of hidden units')\n",
    "parser.add_argument('--num_epochs', type=int, default=50, help='number of epochs')\n",
    "parser.add_argument('--lr', type=float, default=0.0021, help='learning rate')\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "import torch.nn as nn\n",
    "class SimpleNN2(nn.Module):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(57, args.num_hidden)\n",
    "        self.linear2 = nn.Linear(args.num_hidden, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: batch_size x 10\n",
    "        x = self.linear1(x)\n",
    "        #question\n",
    "        # batchsize x 5\n",
    "        x = self.linear2(x)\n",
    "        # x: batch_size x 1\n",
    "        x = self.sigmoid(x)\n",
    "        # x: batch_size x 1\n",
    "        return x\n",
    "    \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n",
    "model = SimpleNN2(args)\n",
    "model=model.to(device)\n",
    "\n",
    "# Create an optimizer\n",
    "class Trainer2():\n",
    "\n",
    "    def __init__(self, model, dataloader, args,device):\n",
    "        # model, dataloader, optimizer, loss_fn\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "        self.loss_fn = torch.nn.BCELoss()\n",
    "        self.device = device\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            for (x, y) in self.dataloader:\n",
    "                x=x.to(self.device)\n",
    "                y=y.to(self.device)\n",
    "                y_pred = self.model(x)\n",
    "                y_pred = y_pred.squeeze()\n",
    "                loss = self.loss_fn(y_pred, y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "\n",
    "            print(\"Epoch: {}, Loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "    def test(self,test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            for (x, y) in test_dataloader:\n",
    "                x=x.to(self.device)\n",
    "                y=y.to(self.device)\n",
    "                y_pred = self.model(x)\n",
    "                y_pred = y_pred.squeeze()\n",
    "                loss = self.loss_fn(y_pred, y)\n",
    "                print(\"Test Loss: {}\".format(loss.item()))\n",
    "    \n",
    "\n",
    "\n",
    "#이런식으로 모델에 args라는 인자를 넣어주어 한꺼번에 사용할 수 있음\n",
    "# Create a model\n",
    "#model = SimpleNN2(args)\n",
    "trainer = Trainer2(model, train_dataloader, args,device)\n",
    "\n",
    "# Train the model\n",
    "trainer.train(num_epochs=50)\n",
    "# Test the model\n",
    "\n",
    "trainer.test(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
